{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through creating and monitoring your HITs. \n",
    "\n",
    "It provides methods to create HITs, pretty-print HIT and assignment status, expire/edit HITs, create qualifications, and download collected data. \n",
    "\n",
    "Before continuing, make sure that you have read the README and set all config fields to their desired values.\n",
    "\n",
    "## Requirements: \n",
    "\n",
    "This code requires Python3 and the following packages: \n",
    "- boto3 \n",
    "- beautiful soup 4\n",
    "\n",
    "Before using, you will have to set up an authentication key to use the Amazon API and include it in a credentials file. See here: https://aws.amazon.com/developers/getting-started/python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the config file and establish a connection to MTurk.\n",
    "\n",
    "A connection is made to production or to the sandbox based on values in the config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# path to the config file \n",
    "CONFIG_PATH = \"../config.json\"\n",
    "\n",
    "# where to save downloaded results \n",
    "SAVE_PATH = \"assignments.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import copy\n",
    "\n",
    "USING_PROD = None\n",
    "EXTERNAL_SUBMIT = None\n",
    "\n",
    "# Read config and extract relevant settings\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "    \n",
    "hit_config = config['hitCreation']\n",
    "\n",
    "EXTERNAL_SUBMIT = config['advanced']['externalSubmit']\n",
    "\n",
    "# Connection to production or sandbox \n",
    "if hit_config['production']:\n",
    "    print(\"USING PROD\")\n",
    "    USING_PROD = True\n",
    "    endpoint_url = 'https://mturk-requester.us-east-1.amazonaws.com'\n",
    "    origin=\"production\"\n",
    "else:\n",
    "    print(\"USING SANDBOX\")\n",
    "    USING_PROD = False\n",
    "    endpoint_url = 'https://mturk-requester-sandbox.us-east-1.amazonaws.com'\n",
    "    origin=\"sandbox\"\n",
    "    \n",
    "hit_url = hit_config['taskUrl']\n",
    "# If using an external link, add a querystring origin=sandbox or origin=production \n",
    "# for use in your js logic if you want. Not done for MTurk submits because it breaks the submit link\n",
    "if (config['advanced']['externalSubmit']): \n",
    "    hit_url = \"%s?origin=%s\" % (hit_url, origin)\n",
    "    \n",
    "# Create an API connection\n",
    "session = boto3.session.Session(profile_name='default')\n",
    "cl = session.client('mturk', region_name='us-east-1', endpoint_url=endpoint_url)\n",
    "\n",
    "print(\"Configuring task as external link with data submitted to: %s\" % config['advanced']['externalSubmitUrl'] if EXTERNAL_SUBMIT else \"Configuring task as an iframe within Mturk\")\n",
    "print(\"TASK URL: \" + hit_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make new HIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safety flags that prevent you from accidentally messing up your HITs. \n",
    "# Set to False except when you are performing these specific tasks. \n",
    "ALLOW_HIT_CREATION = False\n",
    "ALLOW_ASSIGNMENT_ADDITION = False\n",
    "ALLOW_CREATE_QUAL = False\n",
    "ALLOW_UPDATE_EXPIRATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of qualifications that you will use to filter potential workers. \n",
    "# These require that workers come from the US and have an approval rating >= 95%\n",
    "# Edit this list to specify different qualifications for workers \n",
    "QUALS = [\n",
    "       {\n",
    "           'QualificationTypeId': '00000000000000000071',\n",
    "           'Comparator': 'EqualTo',\n",
    "           'LocaleValues': [{\n",
    "               'Country': 'US',\n",
    "           }],\n",
    "       },\n",
    "        \n",
    "       {\n",
    "           'QualificationTypeId': '000000000000000000L0',\n",
    "           'Comparator': 'GreaterThanOrEqualTo',\n",
    "           'IntegerValues': [\n",
    "               95\n",
    "           ],\n",
    "       },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for creating HITs. \n",
    "\n",
    "# generic helper that sets metadata fields based on the config file.\n",
    "def create_hit(task, questionText): \n",
    "    response = cl.create_hit(\n",
    "        MaxAssignments=task['numAssignments'],\n",
    "        AutoApprovalDelayInSeconds=604800,\n",
    "        LifetimeInSeconds=task['lifetime'],\n",
    "        AssignmentDurationInSeconds=task['duration'],\n",
    "        Reward=task['rewardAmount'],\n",
    "        Title=task['title'],\n",
    "        Keywords=task['keywords'],\n",
    "        Description=task['description'],\n",
    "        Question=questionText,\n",
    "        QualificationRequirements=QUALS,\n",
    "    )\n",
    "    print(response)\n",
    "    print(\"\\n\")\n",
    "\n",
    "# creates a HIT in the form of an External Question inside an iFrame\n",
    "def create_hit_iframe(task):\n",
    "    questionText = \"<ExternalQuestion xmlns=\\\"http://mechanicalturk.amazonaws.com/AWSMechanicalTurkDataSchemas/\"\n",
    "    questionText += \"2006-07-14/ExternalQuestion.xsd\\\">\\n<ExternalURL>\" + task['taskUrl']\n",
    "    questionText += \"</ExternalURL>\\n  <FrameHeight>700</FrameHeight>\\n</ExternalQuestion>\"\n",
    "    create_hit(task, questionText)\n",
    "    \n",
    "# Helper to create a HIT in the form of a simple UI with a link to an external page and an\n",
    "# input box for a completion code \n",
    "def create_hit_external(task):\n",
    "    with open('questionform_template.xml', 'r') as myfile:\n",
    "        template=myfile.read() \n",
    "    question_xml = template % (hit_config[\"title\"], hit_config[\"description\"], hit_url)\n",
    "    create_hit(task, question_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to launch your HIT! \n",
    "if ALLOW_HIT_CREATION: \n",
    "    if not (hit_config.get('variants', False) or hit_config.get('numTasks', False)): \n",
    "        raise RuntimeError(\"You must specify either hitCreation.numTasks or hitCreation.variants in your config.json file\")\n",
    "    \n",
    "    hit_creation_function = create_hit_external if EXTERNAL_SUBMIT else create_hit_iframe\n",
    "    \n",
    "    if hit_config.get('numTasks', False): \n",
    "        print(\"creating \" + str(hit_config['numTasks']) + \" tasks\")\n",
    "        for i in range(hit_config['numTasks']):\n",
    "            hit_creation_function(hit_config)\n",
    "    else: \n",
    "        print(\"creating \" + str(len(config['variants'])) + \" variants\")\n",
    "        for var in hit_config['variants']: \n",
    "            task = copy.deepcopy(config)\n",
    "            task.update(var)\n",
    "            hit_creation_function(task)\n",
    "else: \n",
    "    raise RuntimeError(\"This action is not currently enabled; set `ALLOW_HIT_CREATION` to true to proceed with this action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIT monitoring helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions that will be useful for monitoring the status of your HIT. See next section for how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contacts MTurk API to get all assignments for a HIT\n",
    "# Returns them in a list. \n",
    "def get_all_assignments(hitid): \n",
    "    assignments = []\n",
    "    should_continue = True\n",
    "    next_token = False\n",
    "    while (should_continue): \n",
    "        args = {\n",
    "            'HITId': hitid, \n",
    "            'MaxResults': 100\n",
    "        }\n",
    "        if (next_token): \n",
    "            args['NextToken'] = next_token\n",
    "        r = cl.list_assignments_for_hit(**args)\n",
    "        next_token = r.get('NextToken', False)\n",
    "        assignments.extend(r[\"Assignments\"])\n",
    "        should_continue = len(r[\"Assignments\"]) > 0\n",
    "    return assignments\n",
    "\n",
    "# Summarizes all hits in `hits` in a human-readable way. \n",
    "# Prints out the HIT Title, id, if it is expired, and how many assignments it has\n",
    "# completed, pending, and left for work. \n",
    "def summarize_hits(hits): \n",
    "    print(len(hits))\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        expiration = hit['Expiration'].replace(tzinfo=None)\n",
    "        is_expired = expiration < datetime.datetime.now()\n",
    "        description = (\"Title: {title}\\n\" \n",
    "        \"ID: {hid}\\n\"\n",
    "        \"\\tAssignments left: {left}\\n\"\n",
    "        \"\\tAssignments completed: {complete}\\n\"\n",
    "        \"\\tAssignments pending: {pending}\\n\"\n",
    "        \"\\tExpired: {exp}\\n\\n\").format(\n",
    "            title=hit['Title'], \n",
    "            hid=hit['HITId'], \n",
    "            left=hit['NumberOfAssignmentsAvailable'], \n",
    "            complete=hit['NumberOfAssignmentsCompleted'], \n",
    "            pending=hit['NumberOfAssignmentsPending'],\n",
    "            exp=str(is_expired)\n",
    "        )\n",
    "        ret += description\n",
    "    print(ret)\n",
    "    \n",
    "# Prints a human-readable summary of all pending/submitted/approved assignments for all hits in `hits`\n",
    "def summarize_assignments(hits):\n",
    "    ret = \"\"\n",
    "    for hit in hits: \n",
    "        hid = hit['HITId']\n",
    "        title =  hit['Title']\n",
    "        name = \"HIT %s: %s\" % (hid, title)\n",
    "        ret += name + \"\\n\"\n",
    "        assignments = get_all_assignments(hid)\n",
    "        if len(assignments) == 0: \n",
    "            ret += \"\\tNo pending/submitted/approved assignments for this HIT\\n\"\n",
    "        for a in assignments: \n",
    "            desc = \"\\tAssignment {aid}\\n\\t\\tStatus: {status}\\n\".format(aid=a['AssignmentId'], status=a['AssignmentStatus'])\n",
    "            ret += desc\n",
    "    print(ret)\n",
    "    \n",
    "# Refreshes data about the requested hits\n",
    "def refresh_hits(): \n",
    "    global hits \n",
    "    global MAX_RESULTS\n",
    "    hits = cl.list_hits(MaxResults=MAX_RESULTS)['HITs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIT monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RESULTS = 10 # set equal to the number of outstanding hits you have \n",
    "\n",
    "# API call to grab HIT data from MTurk \n",
    "hits = cl.list_hits(MaxResults=MAX_RESULTS)['HITs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes all outstanding HITs\n",
    "refresh_hits()\n",
    "summarize_hits(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizes assignments for all oustanding HITs \n",
    "refresh_hits()\n",
    "summarize_assignments(hits)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approve HITs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approves all outstanding assignments for the HITs displayed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approve_all(hits): \n",
    "    num_approved = 0\n",
    "    for hit in hits: \n",
    "        # make sure you keep getting assignments \n",
    "        assignments = get_all_assignments(hit[\"HITId\"])\n",
    "        #print(assignments)\n",
    "        for a in assignments: \n",
    "            if a['AssignmentStatus'] != 'Approved':\n",
    "                print(\"Approving assignment\")\n",
    "                num_approved += 1\n",
    "                cl.approve_assignment(AssignmentId=a['AssignmentId'])\n",
    "    print(\"Approved %d assignments\" % num_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refresh_hits()\n",
    "approve_all(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update expiration or num tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes the expiration date on a HIT to days_from_now days in the future\n",
    "def update_expiration(hitid, days_from_now): \n",
    "    if ALLOW_UPDATE_EXPIRATION: \n",
    "        days = days_from_now*datetime.timedelta(days=1)\n",
    "        expire_time = datetime.datetime.now() + days\n",
    "\n",
    "        response = cl.update_expiration_for_hit(HITId=hitid, ExpireAt=expire_time)\n",
    "        print(response)\n",
    "        return response\n",
    "    else: \n",
    "        raise RuntimeError(\"This action is not currently enabled; set `ALLOW_UPDATE_EXPIRATION` to true to proceed with this action\")\n",
    "    \n",
    "def expire_hit(hit): \n",
    "    return update_expiration(hit, -10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_assignments(hitid, num_assignments): \n",
    "    if ALLOW_ASSIGNMENT_ADDITION: \n",
    "        response = cl.create_additional_assignments_for_hit(\n",
    "            HITId=hitid,\n",
    "            NumberOfAdditionalAssignments=num_assignments\n",
    "        )\n",
    "        print(response)\n",
    "        return response\n",
    "    else: \n",
    "        raise RuntimeError(\"This action is not currently enabled; set `ALLOW_ASSIGNMENT_ADDITION` to true to proceed with this action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to expire a HIT \n",
    "HIT_id_to_expire = \"FILL THIS IN\" \n",
    "expire_hit(HIT_id_to_expire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to add assignments to a HIT \n",
    "HIT_id_to_add_assignments = \"FILL THIS IN\"\n",
    "num_assignments_to_add = 0\n",
    "add_assignments(HIT_id_to_add_assignments, num_assignments_to_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add custom qualifications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a qualification to disqualify workers who have done work before\n",
    "\n",
    "- uses \"negative qualification\" method from https://github.com/cloudyr/MturkR/wiki/qualifications-as-blocks\n",
    "\n",
    "#### NOTE: quals are kept separate for the sandbox and prod. Make sure you are creating and assigning your quals in prod. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of a new qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_QUAL = {\n",
    "    'Name': 'qualName',\n",
    "    'Keywords': 'Keywords for qual',\n",
    "    'Description': 'What is this qual, and why are you assigning it?',\n",
    "    'QualificationTypeStatus': 'Active',\n",
    "    'AutoGranted': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers for creating, viewing, and assigning qualifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registers a custom qualification with MTurk \n",
    "def create_qual(new_qual):\n",
    "    if ALLOW_CREATE_QUAL: \n",
    "        response = cl.create_qualification_type(**new_qual)\n",
    "        print(response)\n",
    "        Id = response['QualificationTypeId']\n",
    "        print(\"id\", Id)\n",
    "        return Id\n",
    "    else: \n",
    "        raise RuntimException(\"This action is not currently enabled; set `ALLOW_CREATE_QUAL` to true to proceed with this action\")\n",
    "        \n",
    "# Gets all the custom quals you have created and prints them\n",
    "def list_quals(): \n",
    "    response = cl.list_qualification_types(\n",
    "            Query='hasCompletedVisualGraphRecallTask',\n",
    "            MustBeRequestable=False\n",
    "    )\n",
    "    print(response)\n",
    "    \n",
    "# Assigns a qualification to a worker \n",
    "def assign_qual(qual_id, worker_ids): \n",
    "    for worker in worker_ids: \n",
    "        response = cl.associate_qualification_with_worker(\n",
    "                QualificationTypeId=qual_id, \n",
    "                WorkerId=worker,\n",
    "                IntegerValue=1,\n",
    "                SendNotification=False\n",
    "        )\n",
    "        print(response)\n",
    "        assert response\n",
    "        \n",
    "# Gets the ids of all workers who worked on a particular hit \n",
    "def get_workers_for_hit(hitid): \n",
    "    a = get_all_assignments(hitid)\n",
    "    workers = [a_['WorkerId'] for a_ in a]\n",
    "    return workers\n",
    "    \n",
    "# Confirms that every worker in worker_ids has qual with qual_id\n",
    "def confirm_quals(qual_id, worker_ids): \n",
    "    for w in worker_ids: \n",
    "        response = cl.get_qualification_score(\n",
    "                QualificationTypeId=qual_id,\n",
    "                WorkerId=w\n",
    "        )\n",
    "        response = response['Qualification']\n",
    "        assert response['Status'] == 'Granted'\n",
    "        assert response['IntegerValue'] == 1\n",
    "        \n",
    "# Assigns qual with `qual_id` to every worker who has completed an assignment for the hit with `hitid`\n",
    "def assign_qual_for_hit(hitid, qual_id): \n",
    "    workers = get_workers_for_hit(hitid)\n",
    "    print(\"got workers\")\n",
    "    assign_qual(qual_id, workers)\n",
    "    print(\"assigned qual\")\n",
    "    confirm_quals(qual_id, workers)\n",
    "    print(\"confirmed qual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following cells to manipulate qualifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to view the custom qualifications you have created\n",
    "list_quals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to create a new qual \n",
    "qual_to_create = {}\n",
    "create_qual(qual_to_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to assign a custom qual to every worker who has done a specific HIT\n",
    "hit_id = \"FILL THIS IN\"\n",
    "qual_id_to_assign = \"FILL THIS IN\"\n",
    "assign_qual_for_hit(hit_id, qual_id_to_assign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper to download data from MTurk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs \n",
    "import pprint\n",
    "\n",
    "def pretty_print(obj):\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(obj)\n",
    "    pp = None\n",
    "\n",
    "# Downloads all the assignments completed for `hits` as a list of dictionaries. \n",
    "# If a download_path is given, also saves that data as json \n",
    "def get_assignment_content(hits, download_path=\"\", should_print=False): \n",
    "    all_responses = []\n",
    "    for hit in hits: \n",
    "        hitid = hit['HITId']\n",
    "        assignments = get_all_assignments(hitid)\n",
    "        for a in assignments:\n",
    "            a_xml = a['Answer']\n",
    "            #print(a_xml)\n",
    "            soup = bs(a_xml, \"html.parser\")\n",
    "            answers = soup.find_all(\"answer\")\n",
    "            #print(answers)\n",
    "            results = {'HITId': a['HITId'], 'AssignmentId': a['AssignmentId'], 'WorkerId': a['WorkerId']}\n",
    "            for ans in answers: \n",
    "                identifier = ans.find('questionidentifier').string\n",
    "                answer = ans.find('freetext').string\n",
    "                try: \n",
    "                    results[identifier] = json.loads(answer)\n",
    "                except:\n",
    "                    results[identifier] = answer\n",
    "            all_responses.append(results)\n",
    "    if should_print: \n",
    "        pretty_print(all_responses)\n",
    "    if download_path: \n",
    "        with open(download_path, 'w') as outfile: \n",
    "            json.dump(all_responses, outfile)\n",
    "    return all_responses\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to download data\n",
    "responses = get_assignment_content(hits, download_path=SAVE_PATH, should_print=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
